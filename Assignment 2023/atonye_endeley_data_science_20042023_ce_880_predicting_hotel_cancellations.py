# -*- coding: utf-8 -*-
"""Atonye Endeley Data Science  20042023 CE_880_Predicting_hotel_cancellations.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DN0QCK7bpYxsi6bNoXkQZYotS4JPkMdR

# **Atonye** **Endeley** **2103195** **Data Science Project Assignment**
# **Predicting the cancellation of hotel booking**

## Cancellation Prediction Model: 86% Accuracy

## Introduction
## Importing
## Exploratory Analysis
## Feature engineering
## Model Selection

Introduction 
The hotel market, worldwide has not yet fully recovered from the recession caused by the COVID-19 pandemic. One of the biggest problems facing this market is cancellation of reservations. Sites like Booking.com have caused cancellation fees to drop in price or even cease to exist, making there no real penalty for a cancellation. Using this dataset the aim is to create an exploratory analysis in order to find patterns that can help solve business problems and optimize profit. This is based mainly to create a predictive machine learning model to classify which reservations will be cancelled.
"""

!pip install plotly --upgrade

!pip install pandas-profiling

"""# **IMPORT LIBRARIES/DATASETS AND VISUALIZE DATA** 
---

# **Importing Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd #data processing
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.offline as py
import plotly.graph_objs as go
import plotly.tools as tls
import pandas_profiling
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
from sklearn.metrics import roc_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from lightgbm import LGBMClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report
# %matplotlib inline

"""## Loading and Organising Data"""

df = pd.read_excel("/content/HotelCancelation.xlsx")
df.head(3)

"""# **Exploratory Analysis**"""

import pandas_profiling
df.profile_report()

profile = df.profile_report()

# Exporting the report to a file

profile.to_file(output_file="Report.html")

"""From the result it is observered that there are no missing or duplicate rows. 
Also reservations last on average two days and during the week, rarely with children and with one or two adults

The next step is to try and find a peak period, that is, a period with a higher number of bookings than the rest of the year.  To do this a graph will be plotted to measure the amount of reserves made per month in each year

"""

# view the size of the data set
df.shape

# view the data types of the data set
df.info()

# check for duplicate values
df[df.duplicated()].count()

import matplotlib.pyplot as plt
sns.countplot(x ='arrival_month', hue = "arrival_year", data = df, palette ="mako")
plt.show()

"""From the graph the low period starts from November to February (i.e month 11 to 2), although it is not certain because the dataset has a low number of years. Next is to analyse  if there is some impact of this low season on the cancelation rate.

# OBS: In the graphs, colour green will be applied to the non_canceled booking and red for the canceled
"""

colours = ['#008000', '#FF0000']

total_entries = len(df)

fig, ax = plt.subplots(figsize=(10, 6))
sns.countplot(x='booking_status', data= df, palette=colours)

for p in ax.patches:
    height = p.get_height()
    percentage = 100 * height / total_entries
    ax.text(p.get_x() + p.get_width() / 2.,
            height + 3,
            f'{percentage:.1f}%',
            ha="center")

ax.set_title('Distribution of reservations by booking status', fontsize=16)
ax.set_xlabel('Booking Status', fontsize=12)
ax.set_ylabel('Count', fontsize=12)

plt.show()

fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 15))
axes = axes.flatten()

months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']

for i, month in enumerate(range(1, 13)):
    ax = axes[i]
    df_month = df[df['arrival_month'] == month]
    ax.set_title(months[i])
    ax.set_ylim(0, 1)
    for j, val in enumerate(df_month['booking_status'].value_counts(normalize=True).sort_index()):
      ax.bar(['canceled', 'not_canceled'][j], val, color = ['#FF0000', '#008000'][j])
      ax.text(['canceled', 'not_canceled'][j], val+0.05, f"{val*100:.0f}%", ha='center')
    
plt.tight_layout()
plt.show()

"""# From the graphs above it can be observed that cancellation peaks in June and July, but drops considerable in the low booking period, well below the average of 32%."""

# import matplotlib.pyplot library and create a new figure with dimensions 15 inches by 10 inches 
import matplotlib.pyplot as plt

fig = plt.figure(figsize=(15, 10))

subplot_titles = ['Total', 'Online', 'Offline', 'Corporate', 'Complementary', 'Aviation']
market_segments = ['', 'Online', 'Offline', 'Corporate', 'Complementary', 'Aviation']

colours = ['#FF0000', '#008000']

for i in range(1, 7):
    ax = fig.add_subplot(3, 2, i)
    ax.set_title(subplot_titles[i-1])
    if market_segments[i-1] == '':
        data = df.groupby('booking_status')['Booking_ID'].count()
        labels = ['canceled', 'not_canceled']
    else:
        data = df[df['market_segment_type'] == market_segments[i-1]].groupby('booking_status')['Booking_ID'].count()
        if market_segments[i-1] == 'Complementary':
            labels = ['not_canceled']
        else:
            labels = ['canceled', 'not_canceled']
            ax.pie(data, autopct='%.0f%%', labels=labels, colors=colours)

plt.show()

fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 15)) # using the matplotlib library to create a figure with subplots for each month of the year
axes = axes.flatten()

months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']

for i, month in enumerate(range(1, 13)):
    ax = axes[i]
    df_month = df[df['arrival_month'] == month]
    ax.set_title(months[i])
    ax.set_ylim(0, 1)
    for j, val in enumerate(df_month['booking_status'].value_counts(normalize=True).sort_index()):
      ax.bar(['canceled', 'not_canceled'][j], val, color = ['#FF0000', '#008000'][j])
      ax.text(['canceled', 'not_canceled'][j], val+0.05, f"{val*100:.0f}%", ha='center')
    
plt.tight_layout()
plt.show()

"""The cancellation rate has a very similar distribution among the market segments, with the exception of the corporate segment which has a much lower cancellation rate

One assumption I had initially regarding the room types is that they would be in increasing order of price, but plotting the average price in each one I saw that was wrong
"""

# Group the data by room_type_reserved and calculate the average adr for each group
room_type_prices = df.groupby('room_type_reserved')['avg_price_per_room'].mean()


# Plot a bar graph of average prices by room type
room_type_prices.plot(kind='bar', figsize=(8, 6), color='#1f77b4')
plt.xlabel('Room Type')
plt.ylabel('Average Daily Rate (ADR)')
plt.title('Average Room Prices by Type')
plt.show()

#convert the room_type_reserved column to integer type using the .astype() method
df['room_type_reserved'] = df['room_type_reserved'].replace({
    'Room_Type 1': 1,
    'Room_Type 2': 2,
    'Room_Type 3': 3,
    'Room_Type 4': 4,
    'Room_Type 5': 5,
    'Room_Type 6': 6,
    'Room_Type 7': 7
})
df['room_type_reserved'] = df['room_type_reserved'].astype(int)

# Set the colours
colours = ['#008000', '#FF0000']

# Generate the density plot
sns.kdeplot(data=df, x='room_type_reserved', hue='booking_status', palette=colours, fill=True)

# Set Title and Labels
plt.title('Density Plot of Booking Status by Room Type')
plt.xlabel('Room Type')
plt.ylabel('Density')

plt.show()

"""Plotting a density plot of the cancellations by room type, one can observe a very homogeneous and proportional distribution

Some hypothetical assumptions where formed as most important during this analysis: the longer length of stay, the greater the chances of cancellation:

The earlier the reservation, the greater the chances of cancellation
The longer length of days to stay, the greater the chances of cancellation
The more expensive the reservation, the lower the chances to cancel
"""

colors = ['#008000', '#FF0000']
sns.kdeplot(data=df, x='lead_time', hue='booking_status', palette=colors, fill=True)

plt.title('Density Plot of Booking Status by Lead Time')
plt.xlabel('Lead Time')
plt.ylabel('Density')

"""Here it is observed that the first hypothesis is correct: Reservations made for the same day or for a few days ahead are almost certain to be fulfilled, but reservations 100 days in advance become more uncertain, until approximately 200 days in advance cancellation becomes more likely"""

df['length_of_stay'] = df['no_of_weekend_nights'] + df['no_of_week_nights']

colors = ['#008000', '#FF0000']
sns.kdeplot(data=df, x='length_of_stay', hue='booking_status', palette=colors, fill=True)

plt.title('Density Plot of Booking Status by Length of stay')
plt.xlabel('Length of stay')
plt.ylabel('Density')

"""The second hypothesis is also true, but in a less discrepant way. Length of stay of up to 5 days tend to be fulfilled more often, unlike longer days."""

sns.boxplot(x='booking_status', y='avg_price_per_room', data=df)

colors = ['#008000', '#FF0000']
sns.kdeplot(data=df, x='avg_price_per_room', hue='booking_status', palette=colors, fill=True)

plt.title('Density Plot of Booking Status by Average price per room')
plt.xlabel('Average price per room')
plt.ylabel('Density')

"""The third hypothesis is not confirmed, the cancellation distribution is quite homogeneous with one exception: Free Reservations. 
Sales or prizes that give a free stay make the reservation always or almost always fulfilled.

Finally, an examination of the heatmap of correlations plotted by pandas.profilling, it is observed that the correlation between the number of special requests and cancellation is very high, i.e. more special requests generate less cancellation. Graphically we have:
"""

colors = ['#008000', '#FF0000']
sns.kdeplot(data=df, x='no_of_special_requests', hue='booking_status', palette=colors, fill=True)

plt.title('Density Plot of Booking Status by no of special requests')
plt.xlabel('Nº of special requests')
plt.ylabel('Density')

"""Confirming what was already expected. At the end of the data treatment I will plot another heatmap for the correlation with the booking_status variable but this time with everything converted to numeric

# **Feature** **Engineering**
"""

#Cleaning the dateset
df.drop(['Booking_ID'],axis=1,inplace=True)    # Booking_ID is useless
print(df.isnull().sum())      # Check abnormal null number

df.drop(df[(df["no_of_adults"]==0) & (df["no_of_children"]==0)].index,axis=0,inplace=True)  #Drop person number = 0
print(df[(df["no_of_adults"]==0) & (df["no_of_children"]>0)]) #Seems abnormal: no adults but have children

df.info()

"""The dataset has 36,275 rows and 19 columns.

Booking_ID, type_of_meal_plan, room_type_reserved, market_segment_type, and booking_status are of object type while the rest columns are numeric.

There are no null values in the dataset.

Booking_ID column is an identifier. Next is to check if each entry of the column is unique.

Observations:

It can be seen that all the entries of this column are unique. Hence, this column would not add any value to the analysis.
Therefore this column can be dropped. Before proceeding to split the data into train and test set.

The categorical variables are transformeed into numeric data, the column for the year of stay is dropped, since this will not be repeated, it does not appear to be valuable for the model.  Before the data is sepaerated into training and testing sets
"""

df.head()

"""#Prepare data for modeling
Models cannot take non-numeric inputs. 
First step create dummy variables for all the categorical variables.
Before splitting the data into train and test sets.

1. Drop the target variable from the original data and store it in a separate dataframe X 
2. Store the target variable in a separate series Y

https://www.kaggle.com/code/chuyuliucs/hotel-booking-analysis-ml
"""

# Defining a Function to Convert Objects to Int (use LabelEncoder().fit_transform)
def object_to_int(dataframe_series):
    if dataframe_series.dtype=='object':
        dataframe_series = LabelEncoder().fit_transform(dataframe_series)
    return dataframe_series
# Change all data to numerical values
df = df.apply(lambda x: object_to_int(x))
X = df.drop(columns = ['booking_status'])
y = df['booking_status'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)# Defining a Function to Convert Objects to Int (use LabelEncoder().fit_transform)
def object_to_int(dataframe_series):
    if dataframe_series.dtype=='object':
        dataframe_series = LabelEncoder().fit_transform(dataframe_series)
    return dataframe_series
# Change all data to numerical values
df = df.apply(lambda x: object_to_int(x))
X = df.drop(columns = ['booking_status'])
y = df['booking_status'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)

#there are features in different value range, scale them to same range

num_cols = ['no_of_children','no_of_weekend_nights','no_of_week_nights','required_car_parking_space',
            'repeated_guest','no_of_previous_cancellations','no_of_previous_bookings_not_canceled','avg_price_per_room',
            'no_of_special_requests','lead_time']
# to make distribution graph
def distplot(feature, frame, color='r'):
    plt.figure(figsize=(8,3))
    plt.title("Distribution for {}".format(feature))
    ax = sns.distplot(frame[feature], color= color)
# to show there arefeatures in different value rage ---- we need to scale them to same range
for feat in num_cols[9:11]: distplot(feat, df)
plt.show()
# Scale them to same range
df_std = pd.DataFrame(StandardScaler().fit_transform(df[num_cols].astype('float64')), columns=num_cols)

"""SUPPORT VECTOR CLASSIFIER (SVC)


"""

svc_model = SVC()
svc_model.fit(X_train, y_train)
predict_y = svc_model.predict(X_test)
accuracy_svc = svc_model.score(X_test, y_test)
print("SVM accuracy is :", accuracy_svc)
print('-' * 60)
print(classification_report(y_test, predict_y))
print('-' * 60)
plt.figure(figsize=(4, 3))
# macro-average F1-score of 0.69 and a weighted-average F1-score of 0.74. This means that the overall performance
# of the model is better captured by the weighted-average because the dataset is imbalanced
# (class 1 has more samples than class 0)
sns.heatmap(confusion_matrix(y_test, predict_y),
            annot=True, fmt="d", linecolor="k", linewidths=3)
# to understand the graph: the (0,0) value represents the number of instances that were actually in class 0 and were correctly predicted to be in class 0
plt.title("Support Vector Clasiffier Confusion Matrix", fontsize=14)
plt.show()

#RANDOM FOREST CLASSIFIER
model_rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,
                                  random_state =65, max_features = "auto",
                                  max_leaf_nodes = 35)
model_rf.fit(X_train, y_train)

# Make predictions
prediction_test = model_rf.predict(X_test)
print (metrics.accuracy_score(y_test, prediction_test))
print('-'*60)

# 500, 50, 30
print(classification_report(y_test, prediction_test))
print('-'*60)

plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, prediction_test),annot=True,fmt = "d",linecolor="k",linewidths=3)

plt.title(" Random Forest Confusion Matrix",fontsize=14)
plt.show()
print('-'*60)

y_rfpred_prob = model_rf.predict_proba(X_test)[:,1]
fpr_rf, tpr_rf, thresholds = roc_curve(y_test, y_rfpred_prob)
plt.figure(figsize=(8, 5))
plt.plot([0, 1], [0, 1], 'k--' )
plt.plot(fpr_rf, tpr_rf, label='Random Forest',color = "r")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Random Forest ROC Curve',fontsize=16)
plt.show()

"""LOGISTIC REGRESSION


"""

#LOGISTIC REGRESSION
lr_model = LogisticRegression()
lr_model.fit(X_train,y_train)
accuracy_lr = lr_model.score(X_test,y_test)
print("Logistic Regression accuracy is :",accuracy_lr)
print('-'*60)

lr_pred= lr_model.predict(X_test)
report = classification_report(y_test,lr_pred)
print(report)

print('-'*60)

plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, lr_pred),annot=True,fmt = "d",linecolor="k",linewidths=3)
plt.title("Logistic Regression Confusion Matrix",fontsize=14)
plt.show()

print('-'*60)

y_pred_prob = lr_model.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
plt.figure(figsize=(7, 4))

plt.plot([0, 1], [0, 1], 'k--' )
plt.plot(fpr, tpr, label='Logistic Regression',color = "r")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Logistic Regression ROC Curve',fontsize=16)
plt.show();

"""**# DECISION TREE CLASSIFIER**"""

# DECISION TREE CLASSIFIER
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train,y_train)
predictdt_y = dt_model.predict(X_test)
accuracy_dt = dt_model.score(X_test,y_test)
print("Decision Tree accuracy is :",accuracy_dt)

print(classification_report(y_test, predictdt_y))

plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, predictdt_y),annot=True,fmt = "d",linecolor="k",linewidths=3)
plt.title("Decision Tree Confusion Matrix",fontsize=14)
plt.show()

y_pred_prob = dt_model.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
plt.figure(figsize=(7, 4))

plt.plot([0, 1], [0, 1], 'k--' )
plt.plot(fpr, tpr, label='Logistic Regression',color = "r")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Logistic Regression Classifier ROC Curve',fontsize=16)
plt.show();

df.to_csv('HotelCancelation_880.csv')